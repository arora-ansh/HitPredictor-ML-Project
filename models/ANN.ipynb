{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y(dataY):\n",
    "    y = []\n",
    "    for i in range (len(dataY)):\n",
    "        if(dataY[i] > 50):\n",
    "            y.append(0)\n",
    "        else:\n",
    "            y.append(1)\n",
    "    return np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Explicit</th>\n",
       "      <th>Artist_followers</th>\n",
       "      <th>Track_number_on_album</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Key</th>\n",
       "      <th>Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.112882</td>\n",
       "      <td>1.012971</td>\n",
       "      <td>-0.703623</td>\n",
       "      <td>-0.253508</td>\n",
       "      <td>-0.056900</td>\n",
       "      <td>-0.257351</td>\n",
       "      <td>-0.321798</td>\n",
       "      <td>-0.287111</td>\n",
       "      <td>1.295366</td>\n",
       "      <td>2.132090</td>\n",
       "      <td>0.865448</td>\n",
       "      <td>0.478965</td>\n",
       "      <td>0.209096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.898356</td>\n",
       "      <td>0.172558</td>\n",
       "      <td>-0.703623</td>\n",
       "      <td>0.798171</td>\n",
       "      <td>0.424214</td>\n",
       "      <td>-0.688588</td>\n",
       "      <td>-0.492682</td>\n",
       "      <td>0.282796</td>\n",
       "      <td>-0.811102</td>\n",
       "      <td>-0.910119</td>\n",
       "      <td>0.865448</td>\n",
       "      <td>0.752338</td>\n",
       "      <td>0.774957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.898356</td>\n",
       "      <td>-0.658039</td>\n",
       "      <td>-0.703623</td>\n",
       "      <td>0.764382</td>\n",
       "      <td>0.223151</td>\n",
       "      <td>0.783781</td>\n",
       "      <td>0.019972</td>\n",
       "      <td>0.893382</td>\n",
       "      <td>-0.654093</td>\n",
       "      <td>-0.677720</td>\n",
       "      <td>-1.155199</td>\n",
       "      <td>1.025710</td>\n",
       "      <td>1.138724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.898356</td>\n",
       "      <td>-0.471741</td>\n",
       "      <td>1.732316</td>\n",
       "      <td>-0.619272</td>\n",
       "      <td>-1.528965</td>\n",
       "      <td>0.506556</td>\n",
       "      <td>-0.410955</td>\n",
       "      <td>0.398452</td>\n",
       "      <td>-0.609112</td>\n",
       "      <td>2.593547</td>\n",
       "      <td>0.865448</td>\n",
       "      <td>0.752338</td>\n",
       "      <td>-1.555849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.898356</td>\n",
       "      <td>0.029319</td>\n",
       "      <td>-0.703623</td>\n",
       "      <td>-0.683893</td>\n",
       "      <td>0.330863</td>\n",
       "      <td>-1.138308</td>\n",
       "      <td>1.097289</td>\n",
       "      <td>-0.823916</td>\n",
       "      <td>-0.601473</td>\n",
       "      <td>-0.142817</td>\n",
       "      <td>0.865448</td>\n",
       "      <td>-1.434643</td>\n",
       "      <td>-1.806445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Explicit  Artist_followers  Track_number_on_album  Acousticness  \\\n",
       "0  1.112882          1.012971              -0.703623     -0.253508   \n",
       "1 -0.898356          0.172558              -0.703623      0.798171   \n",
       "2 -0.898356         -0.658039              -0.703623      0.764382   \n",
       "3 -0.898356         -0.471741               1.732316     -0.619272   \n",
       "4 -0.898356          0.029319              -0.703623     -0.683893   \n",
       "\n",
       "   Danceability    Energy  Liveness  Loudness  Speechiness     Tempo  \\\n",
       "0     -0.056900 -0.257351 -0.321798 -0.287111     1.295366  2.132090   \n",
       "1      0.424214 -0.688588 -0.492682  0.282796    -0.811102 -0.910119   \n",
       "2      0.223151  0.783781  0.019972  0.893382    -0.654093 -0.677720   \n",
       "3     -1.528965  0.506556 -0.410955  0.398452    -0.609112  2.593547   \n",
       "4      0.330863 -1.138308  1.097289 -0.823916    -0.601473 -0.142817   \n",
       "\n",
       "       Mode       Key   Valence  \n",
       "0  0.865448  0.478965  0.209096  \n",
       "1  0.865448  0.752338  0.774957  \n",
       "2 -1.155199  1.025710  1.138724  \n",
       "3  0.865448  0.752338 -1.555849  \n",
       "4  0.865448 -1.434643 -1.806445  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX = pd.read_csv('../datasets/spotofy_music_normalized.csv')\n",
    "dataY = pd.read_csv('../datasets/spotofy_music_labels.csv')\n",
    "dataY_multi = pd.read_csv('../datasets/spotofy_music_labels.csv')\n",
    "Y = convert_y(np.array(dataY))\n",
    "dataX.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement ANNs on the above data and see the accuracy scores of its prediction of hit vs not hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(13, input_dim=13, activation='relu'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid')) #Single Layer Sigmoid Binary Classifier == Logistic Regression\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-92b082f334d5>:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  estimator = KerasClassifier(build_fn=create_baseline, epochs=25, batch_size=5, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline with Un-Standardized Data, KFold with K = 5: 68.66% (1.39%)\n",
      "Baseline with Standardized Data, KFold with K = 5: 68.94% (1.08%)\n"
     ]
    }
   ],
   "source": [
    "# evaluate model with standardized dataset\n",
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=25, batch_size=5, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "results = cross_val_score(estimator, dataX, Y, cv=kfold)\n",
    "print(\"Baseline with Un-Standardized Data, KFold with K = 5: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "results2 = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Baseline with Standardized Data, KFold with K = 5: %.2f%% (%.2f%%)\" % (results2.mean()*100, results2.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neural_network(activation = \"relu\", neurons = 5):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, activation='relu'))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(3,activation=\"relu\"))\n",
    "    model.add(Dense(1, activation='sigmoid')) #Single Layer Sigmoid Binary Classifier == Logistic Regression\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-9-11f61cdd3f81>:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  estimators.append(('mlp', KerasClassifier(build_fn=create_neural_network, epochs=40, batch_size=5, verbose=1)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "567/567 [==============================] - 3s 4ms/step - loss: 0.6342 - accuracy: 0.6514\n",
      "Epoch 2/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.6130 - accuracy: 0.6690\n",
      "Epoch 3/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.6051 - accuracy: 0.6782\n",
      "Epoch 4/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5989 - accuracy: 0.6867\n",
      "Epoch 5/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5941 - accuracy: 0.6952\n",
      "Epoch 6/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5923 - accuracy: 0.6959\n",
      "Epoch 7/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5893 - accuracy: 0.7015\n",
      "Epoch 8/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5869 - accuracy: 0.6976\n",
      "Epoch 9/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5847 - accuracy: 0.7033\n",
      "Epoch 10/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5817 - accuracy: 0.7079\n",
      "Epoch 11/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5799 - accuracy: 0.7093\n",
      "Epoch 12/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5782 - accuracy: 0.7114\n",
      "Epoch 13/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5756 - accuracy: 0.7114\n",
      "Epoch 14/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5738 - accuracy: 0.7156\n",
      "Epoch 15/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5722 - accuracy: 0.7160\n",
      "Epoch 16/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5708 - accuracy: 0.7142\n",
      "Epoch 17/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5684 - accuracy: 0.7149\n",
      "Epoch 18/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7188\n",
      "Epoch 19/40\n",
      "567/567 [==============================] - 1s 3ms/step - loss: 0.5675 - accuracy: 0.7167\n",
      "Epoch 20/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5649 - accuracy: 0.7149\n",
      "Epoch 21/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5634 - accuracy: 0.7192\n",
      "Epoch 22/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5626 - accuracy: 0.7188\n",
      "Epoch 23/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5613 - accuracy: 0.7192\n",
      "Epoch 24/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5600 - accuracy: 0.7231\n",
      "Epoch 25/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5581 - accuracy: 0.7248\n",
      "Epoch 26/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5595 - accuracy: 0.7206\n",
      "Epoch 27/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5578 - accuracy: 0.7231\n",
      "Epoch 28/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5566 - accuracy: 0.7224\n",
      "Epoch 29/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5550 - accuracy: 0.7262\n",
      "Epoch 30/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5548 - accuracy: 0.7231\n",
      "Epoch 31/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5539 - accuracy: 0.7262\n",
      "Epoch 32/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5535 - accuracy: 0.7277\n",
      "Epoch 33/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5536 - accuracy: 0.7248\n",
      "Epoch 34/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5532 - accuracy: 0.7330\n",
      "Epoch 35/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5524 - accuracy: 0.7234\n",
      "Epoch 36/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5518 - accuracy: 0.7347\n",
      "Epoch 37/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5509 - accuracy: 0.7294\n",
      "Epoch 38/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5509 - accuracy: 0.7315\n",
      "Epoch 39/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5504 - accuracy: 0.7298\n",
      "Epoch 40/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5484 - accuracy: 0.7273\n",
      "284/284 [==============================] - 1s 2ms/step - loss: 0.6239 - accuracy: 0.6758\n",
      "Epoch 1/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.6637 - accuracy: 0.6337\n",
      "Epoch 2/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.6312 - accuracy: 0.6637\n",
      "Epoch 3/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.6207 - accuracy: 0.6637\n",
      "Epoch 4/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.6114 - accuracy: 0.6641\n",
      "Epoch 5/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.6022 - accuracy: 0.6655\n",
      "Epoch 6/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5951 - accuracy: 0.6651\n",
      "Epoch 7/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5894 - accuracy: 0.6701\n",
      "Epoch 8/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5855 - accuracy: 0.6945\n",
      "Epoch 9/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5832 - accuracy: 0.6994\n",
      "Epoch 10/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5817 - accuracy: 0.6987\n",
      "Epoch 11/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5788 - accuracy: 0.7033\n",
      "Epoch 12/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5780 - accuracy: 0.7022\n",
      "Epoch 13/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5759 - accuracy: 0.6998\n",
      "Epoch 14/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5739 - accuracy: 0.7068\n",
      "Epoch 15/40\n",
      "567/567 [==============================] - 4s 8ms/step - loss: 0.5724 - accuracy: 0.7061\n",
      "Epoch 16/40\n",
      "567/567 [==============================] - 3s 6ms/step - loss: 0.5708 - accuracy: 0.7036\n",
      "Epoch 17/40\n",
      "567/567 [==============================] - 3s 5ms/step - loss: 0.5698 - accuracy: 0.7114\n",
      "Epoch 18/40\n",
      "567/567 [==============================] - 3s 5ms/step - loss: 0.5685 - accuracy: 0.7100\n",
      "Epoch 19/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5657 - accuracy: 0.7121\n",
      "Epoch 20/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5663 - accuracy: 0.7142\n",
      "Epoch 21/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5647 - accuracy: 0.7149\n",
      "Epoch 22/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5640 - accuracy: 0.7153\n",
      "Epoch 23/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5618 - accuracy: 0.7132\n",
      "Epoch 24/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5617 - accuracy: 0.7178\n",
      "Epoch 25/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5624 - accuracy: 0.7160\n",
      "Epoch 26/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5599 - accuracy: 0.7164\n",
      "Epoch 27/40\n",
      "567/567 [==============================] - 1s 3ms/step - loss: 0.5588 - accuracy: 0.7171\n",
      "Epoch 28/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5575 - accuracy: 0.7199\n",
      "Epoch 29/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5574 - accuracy: 0.7185\n",
      "Epoch 30/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5563 - accuracy: 0.7174\n",
      "Epoch 31/40\n",
      "567/567 [==============================] - 1s 3ms/step - loss: 0.5560 - accuracy: 0.7174\n",
      "Epoch 32/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5556 - accuracy: 0.7217\n",
      "Epoch 33/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5569 - accuracy: 0.7156\n",
      "Epoch 34/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5540 - accuracy: 0.7167\n",
      "Epoch 35/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5531 - accuracy: 0.7234\n",
      "Epoch 36/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5533 - accuracy: 0.7227\n",
      "Epoch 37/40\n",
      "567/567 [==============================] - 3s 6ms/step - loss: 0.5533 - accuracy: 0.7199\n",
      "Epoch 38/40\n",
      "567/567 [==============================] - 4s 7ms/step - loss: 0.5511 - accuracy: 0.7188\n",
      "Epoch 39/40\n",
      "567/567 [==============================] - 3s 5ms/step - loss: 0.5504 - accuracy: 0.7213\n",
      "Epoch 40/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5499 - accuracy: 0.7234\n",
      "284/284 [==============================] - 2s 4ms/step - loss: 0.6360 - accuracy: 0.6737\n",
      "Epoch 1/40\n",
      "567/567 [==============================] - 3s 5ms/step - loss: 0.6736 - accuracy: 0.6419\n",
      "Epoch 2/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.6442 - accuracy: 0.6638\n",
      "Epoch 3/40\n",
      "567/567 [==============================] - 3s 5ms/step - loss: 0.6318 - accuracy: 0.6638\n",
      "Epoch 4/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.6178 - accuracy: 0.6734\n",
      "Epoch 5/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.6050 - accuracy: 0.6857\n",
      "Epoch 6/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5988 - accuracy: 0.6864\n",
      "Epoch 7/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5961 - accuracy: 0.6903\n",
      "Epoch 8/40\n",
      "567/567 [==============================] - 3s 6ms/step - loss: 0.5929 - accuracy: 0.6875\n",
      "Epoch 9/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5912 - accuracy: 0.6921\n",
      "Epoch 10/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5892 - accuracy: 0.6924\n",
      "Epoch 11/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5888 - accuracy: 0.6995\n",
      "Epoch 12/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5865 - accuracy: 0.6942\n",
      "Epoch 13/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5865 - accuracy: 0.6953\n",
      "Epoch 14/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5851 - accuracy: 0.7006\n",
      "Epoch 15/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5833 - accuracy: 0.6953\n",
      "Epoch 16/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5823 - accuracy: 0.6992\n",
      "Epoch 17/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5819 - accuracy: 0.6977\n",
      "Epoch 18/40\n",
      "567/567 [==============================] - 1s 3ms/step - loss: 0.5800 - accuracy: 0.7037\n",
      "Epoch 19/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5788 - accuracy: 0.7023\n",
      "Epoch 20/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5792 - accuracy: 0.7037\n",
      "Epoch 21/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5775 - accuracy: 0.7013\n",
      "Epoch 22/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5761 - accuracy: 0.7062\n",
      "Epoch 23/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5770 - accuracy: 0.7016\n",
      "Epoch 24/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5752 - accuracy: 0.7044\n",
      "Epoch 25/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5750 - accuracy: 0.7027\n",
      "Epoch 26/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5738 - accuracy: 0.7044\n",
      "Epoch 27/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5747 - accuracy: 0.7055\n",
      "Epoch 28/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5729 - accuracy: 0.7037\n",
      "Epoch 29/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5723 - accuracy: 0.7059\n",
      "Epoch 30/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5719 - accuracy: 0.7069\n",
      "Epoch 31/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5710 - accuracy: 0.7044\n",
      "Epoch 32/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5707 - accuracy: 0.7080\n",
      "Epoch 33/40\n",
      "567/567 [==============================] - 3s 5ms/step - loss: 0.5698 - accuracy: 0.7052\n",
      "Epoch 34/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5682 - accuracy: 0.7055\n",
      "Epoch 35/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5681 - accuracy: 0.7122\n",
      "Epoch 36/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5673 - accuracy: 0.7094\n",
      "Epoch 37/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5672 - accuracy: 0.7090\n",
      "Epoch 38/40\n",
      "567/567 [==============================] - 2s 4ms/step - loss: 0.5662 - accuracy: 0.7097\n",
      "Epoch 39/40\n",
      "567/567 [==============================] - 3s 5ms/step - loss: 0.5656 - accuracy: 0.7129\n",
      "Epoch 40/40\n",
      "567/567 [==============================] - 3s 5ms/step - loss: 0.5640 - accuracy: 0.7122\n",
      "283/283 [==============================] - 2s 5ms/step - loss: 0.6109 - accuracy: 0.6933\n",
      "NN Accuracy: 68.10% (0.88%)\n"
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_neural_network, epochs=40, batch_size=5, verbose=1)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "results = cross_val_score(pipeline, dataX, Y, cv=kfold)\n",
    "print(\"NN Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the ReLU activation function on running for 25 epochs, the K-Fold CV accuracy on K=3 comes out to be 73.5% and the accuracy on K=5 is 71.5%. The Neural Network model trained was a simple one with one hidden layer with 5 neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the tanh activation function on running for 40 epochs, the K-Fold CV accuracy on K=3 comes out to be 66.89%. The Neural Network model trained was a simple one with one hidden layer with 10 neurons.\n",
    "and the accuracy on K=5 is 67.93% --> hiddlen layer with 5 neurons\n",
    "\n",
    "> Accuracy: 66.89% (1.32%)\n",
    "\n",
    ">Accuracy: 67.93% (0.89%)\n",
    "\n",
    ">Accuracy: 69.20% (0.90%) --> leaky_relu, 5 neurons, k=5\n",
    "\n",
    ">NN Accuracy: 68.75% (0.31%) --> leaky_relu, 5 neurons, k=3\n",
    "\n",
    ">NN Accuracy: 71.3% (1.16%) --> tanh , 5 neurons, k=5, epcohs 25\n",
    "\n",
    "> Accuracy : 71.8% --> tanh, 5 neurons, standarized, 40 epoch, k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67647058, 0.68470585, 0.67491168, 0.6949352 , 0.65135455])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
