{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y(dataY):\n",
    "    y = []\n",
    "    for i in range (len(dataY)):\n",
    "        if(dataY[i] > 50):\n",
    "            y.append(0)\n",
    "        else:\n",
    "            y.append(1)\n",
    "    return np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Explicit</th>\n",
       "      <th>Artist_followers</th>\n",
       "      <th>Track_number_on_album</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Key</th>\n",
       "      <th>Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.112882</td>\n",
       "      <td>1.012971</td>\n",
       "      <td>-0.703623</td>\n",
       "      <td>-0.253508</td>\n",
       "      <td>-0.056900</td>\n",
       "      <td>-0.257351</td>\n",
       "      <td>-0.321798</td>\n",
       "      <td>-0.287111</td>\n",
       "      <td>1.295366</td>\n",
       "      <td>2.132090</td>\n",
       "      <td>0.865448</td>\n",
       "      <td>0.478965</td>\n",
       "      <td>0.209096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.898356</td>\n",
       "      <td>0.172558</td>\n",
       "      <td>-0.703623</td>\n",
       "      <td>0.798171</td>\n",
       "      <td>0.424214</td>\n",
       "      <td>-0.688588</td>\n",
       "      <td>-0.492682</td>\n",
       "      <td>0.282796</td>\n",
       "      <td>-0.811102</td>\n",
       "      <td>-0.910119</td>\n",
       "      <td>0.865448</td>\n",
       "      <td>0.752338</td>\n",
       "      <td>0.774957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.898356</td>\n",
       "      <td>-0.658039</td>\n",
       "      <td>-0.703623</td>\n",
       "      <td>0.764382</td>\n",
       "      <td>0.223151</td>\n",
       "      <td>0.783781</td>\n",
       "      <td>0.019972</td>\n",
       "      <td>0.893382</td>\n",
       "      <td>-0.654093</td>\n",
       "      <td>-0.677720</td>\n",
       "      <td>-1.155199</td>\n",
       "      <td>1.025710</td>\n",
       "      <td>1.138724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.898356</td>\n",
       "      <td>-0.471741</td>\n",
       "      <td>1.732316</td>\n",
       "      <td>-0.619272</td>\n",
       "      <td>-1.528965</td>\n",
       "      <td>0.506556</td>\n",
       "      <td>-0.410955</td>\n",
       "      <td>0.398452</td>\n",
       "      <td>-0.609112</td>\n",
       "      <td>2.593547</td>\n",
       "      <td>0.865448</td>\n",
       "      <td>0.752338</td>\n",
       "      <td>-1.555849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.898356</td>\n",
       "      <td>0.029319</td>\n",
       "      <td>-0.703623</td>\n",
       "      <td>-0.683893</td>\n",
       "      <td>0.330863</td>\n",
       "      <td>-1.138308</td>\n",
       "      <td>1.097289</td>\n",
       "      <td>-0.823916</td>\n",
       "      <td>-0.601473</td>\n",
       "      <td>-0.142817</td>\n",
       "      <td>0.865448</td>\n",
       "      <td>-1.434643</td>\n",
       "      <td>-1.806445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Explicit  Artist_followers  Track_number_on_album  Acousticness  \\\n",
       "0  1.112882          1.012971              -0.703623     -0.253508   \n",
       "1 -0.898356          0.172558              -0.703623      0.798171   \n",
       "2 -0.898356         -0.658039              -0.703623      0.764382   \n",
       "3 -0.898356         -0.471741               1.732316     -0.619272   \n",
       "4 -0.898356          0.029319              -0.703623     -0.683893   \n",
       "\n",
       "   Danceability    Energy  Liveness  Loudness  Speechiness     Tempo  \\\n",
       "0     -0.056900 -0.257351 -0.321798 -0.287111     1.295366  2.132090   \n",
       "1      0.424214 -0.688588 -0.492682  0.282796    -0.811102 -0.910119   \n",
       "2      0.223151  0.783781  0.019972  0.893382    -0.654093 -0.677720   \n",
       "3     -1.528965  0.506556 -0.410955  0.398452    -0.609112  2.593547   \n",
       "4      0.330863 -1.138308  1.097289 -0.823916    -0.601473 -0.142817   \n",
       "\n",
       "       Mode       Key   Valence  \n",
       "0  0.865448  0.478965  0.209096  \n",
       "1  0.865448  0.752338  0.774957  \n",
       "2 -1.155199  1.025710  1.138724  \n",
       "3  0.865448  0.752338 -1.555849  \n",
       "4  0.865448 -1.434643 -1.806445  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX = pd.read_csv('./datasets/spotofy_music_normalized.csv')\n",
    "dataY = pd.read_csv('./datasets/spotofy_music_labels.csv')\n",
    "dataY_multi = pd.read_csv('./datasets/spotofy_music_labels.csv')\n",
    "Y = convert_y(np.array(dataY))\n",
    "dataX.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement ANNs on the above data and see the accuracy scores of its prediction of hit vs not hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(13, input_dim=13, activation='relu'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid')) #Single Layer Sigmoid Binary Classifier == Logistic Regression\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-92b082f334d5>:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  estimator = KerasClassifier(build_fn=create_baseline, epochs=25, batch_size=5, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline with Un-Standardized Data, KFold with K = 5: 68.66% (1.39%)\n",
      "Baseline with Standardized Data, KFold with K = 5: 68.94% (1.08%)\n"
     ]
    }
   ],
   "source": [
    "# evaluate model with standardized dataset\n",
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=25, batch_size=5, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "results = cross_val_score(estimator, dataX, Y, cv=kfold)\n",
    "print(\"Baseline with Un-Standardized Data, KFold with K = 5: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "results2 = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Baseline with Standardized Data, KFold with K = 5: %.2f%% (%.2f%%)\" % (results2.mean()*100, results2.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neural_network():\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, activation='relu'))\n",
    "    model.add(Dense(5, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid')) #Single Layer Sigmoid Binary Classifier == Logistic Regression\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-30-6d7fa63c98e7>:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  estimators.append(('mlp', KerasClassifier(build_fn=create_neural_network, epochs=40, batch_size=5, verbose=1)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "567/567 [==============================] - 2s 2ms/step - loss: 0.6621 - accuracy: 0.6323\n",
      "Epoch 2/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.6267 - accuracy: 0.6644\n",
      "Epoch 3/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.6111 - accuracy: 0.6718\n",
      "Epoch 4/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.6016 - accuracy: 0.6867\n",
      "Epoch 5/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5961 - accuracy: 0.6913\n",
      "Epoch 6/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5933 - accuracy: 0.6895\n",
      "Epoch 7/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5911 - accuracy: 0.6913\n",
      "Epoch 8/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5886 - accuracy: 0.6906\n",
      "Epoch 9/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5874 - accuracy: 0.6952\n",
      "Epoch 10/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5857 - accuracy: 0.6916\n",
      "Epoch 11/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5838 - accuracy: 0.6955\n",
      "Epoch 12/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5817 - accuracy: 0.6987\n",
      "Epoch 13/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5801 - accuracy: 0.6987\n",
      "Epoch 14/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5778 - accuracy: 0.6959\n",
      "Epoch 15/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5756 - accuracy: 0.7026\n",
      "Epoch 16/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5740 - accuracy: 0.7051\n",
      "Epoch 17/40\n",
      "567/567 [==============================] - 1s 3ms/step - loss: 0.5727 - accuracy: 0.7043\n",
      "Epoch 18/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5712 - accuracy: 0.7061\n",
      "Epoch 19/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5699 - accuracy: 0.7125\n",
      "Epoch 20/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5693 - accuracy: 0.7040\n",
      "Epoch 21/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5681 - accuracy: 0.7082\n",
      "Epoch 22/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5668 - accuracy: 0.7058\n",
      "Epoch 23/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5655 - accuracy: 0.7107\n",
      "Epoch 24/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5647 - accuracy: 0.7082\n",
      "Epoch 25/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5636 - accuracy: 0.7153\n",
      "Epoch 26/40\n",
      "567/567 [==============================] - 1s 3ms/step - loss: 0.5634 - accuracy: 0.7153\n",
      "Epoch 27/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5621 - accuracy: 0.7156\n",
      "Epoch 28/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5608 - accuracy: 0.7121\n",
      "Epoch 29/40\n",
      "567/567 [==============================] - 1s 3ms/step - loss: 0.5608 - accuracy: 0.7125\n",
      "Epoch 30/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5599 - accuracy: 0.7146\n",
      "Epoch 31/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5598 - accuracy: 0.7181\n",
      "Epoch 32/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5587 - accuracy: 0.7181\n",
      "Epoch 33/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5565 - accuracy: 0.7164\n",
      "Epoch 34/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5568 - accuracy: 0.7178\n",
      "Epoch 35/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5572 - accuracy: 0.7146\n",
      "Epoch 36/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5560 - accuracy: 0.7185\n",
      "Epoch 37/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5556 - accuracy: 0.7185\n",
      "Epoch 38/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5539 - accuracy: 0.7199\n",
      "Epoch 39/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5545 - accuracy: 0.7202\n",
      "Epoch 40/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5545 - accuracy: 0.7188\n",
      "284/284 [==============================] - 1s 2ms/step - loss: 0.6175 - accuracy: 0.6766\n",
      "Epoch 1/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.6606 - accuracy: 0.6192\n",
      "Epoch 2/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.6202 - accuracy: 0.6676\n",
      "Epoch 3/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.6073 - accuracy: 0.6856\n",
      "Epoch 4/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5998 - accuracy: 0.6930\n",
      "Epoch 5/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5948 - accuracy: 0.6952\n",
      "Epoch 6/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5919 - accuracy: 0.6952\n",
      "Epoch 7/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5895 - accuracy: 0.6945\n",
      "Epoch 8/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5879 - accuracy: 0.6952\n",
      "Epoch 9/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5864 - accuracy: 0.6973\n",
      "Epoch 10/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5852 - accuracy: 0.6966\n",
      "Epoch 11/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5827 - accuracy: 0.6973\n",
      "Epoch 12/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5827 - accuracy: 0.6980\n",
      "Epoch 13/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5812 - accuracy: 0.6987\n",
      "Epoch 14/40\n",
      "567/567 [==============================] - 1s 3ms/step - loss: 0.5802 - accuracy: 0.6973\n",
      "Epoch 15/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5793 - accuracy: 0.6973\n",
      "Epoch 16/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5785 - accuracy: 0.7022\n",
      "Epoch 17/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5776 - accuracy: 0.7019\n",
      "Epoch 18/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5764 - accuracy: 0.7033\n",
      "Epoch 19/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5753 - accuracy: 0.7043\n",
      "Epoch 20/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5745 - accuracy: 0.7072\n",
      "Epoch 21/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5735 - accuracy: 0.7079\n",
      "Epoch 22/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5719 - accuracy: 0.7061\n",
      "Epoch 23/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5723 - accuracy: 0.7093\n",
      "Epoch 24/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5708 - accuracy: 0.7061\n",
      "Epoch 25/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5696 - accuracy: 0.7103\n",
      "Epoch 26/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5695 - accuracy: 0.7121\n",
      "Epoch 27/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5693 - accuracy: 0.7079\n",
      "Epoch 28/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5676 - accuracy: 0.7128\n",
      "Epoch 29/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5675 - accuracy: 0.7093\n",
      "Epoch 30/40\n",
      "567/567 [==============================] - 1s 3ms/step - loss: 0.5665 - accuracy: 0.7118\n",
      "Epoch 31/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5657 - accuracy: 0.7103\n",
      "Epoch 32/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5651 - accuracy: 0.7139\n",
      "Epoch 33/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5648 - accuracy: 0.7149\n",
      "Epoch 34/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5642 - accuracy: 0.7156\n",
      "Epoch 35/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5638 - accuracy: 0.7164\n",
      "Epoch 36/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5636 - accuracy: 0.7181\n",
      "Epoch 37/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5627 - accuracy: 0.7160\n",
      "Epoch 38/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5622 - accuracy: 0.7195\n",
      "Epoch 39/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5614 - accuracy: 0.7164\n",
      "Epoch 40/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5612 - accuracy: 0.7181\n",
      "284/284 [==============================] - 1s 2ms/step - loss: 0.6182 - accuracy: 0.6992\n",
      "Epoch 1/40\n",
      "567/567 [==============================] - 2s 2ms/step - loss: 0.6549 - accuracy: 0.6582\n",
      "Epoch 2/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.6133 - accuracy: 0.6843\n",
      "Epoch 3/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.6030 - accuracy: 0.6903\n",
      "Epoch 4/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5976 - accuracy: 0.6960\n",
      "Epoch 5/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5938 - accuracy: 0.6949\n",
      "Epoch 6/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5913 - accuracy: 0.6977\n",
      "Epoch 7/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5896 - accuracy: 0.7020\n",
      "Epoch 8/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5871 - accuracy: 0.7006\n",
      "Epoch 9/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5853 - accuracy: 0.7030\n",
      "Epoch 10/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5836 - accuracy: 0.7009\n",
      "Epoch 11/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5819 - accuracy: 0.7052\n",
      "Epoch 12/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5803 - accuracy: 0.7080\n",
      "Epoch 13/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5792 - accuracy: 0.7066\n",
      "Epoch 14/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5777 - accuracy: 0.7090\n",
      "Epoch 15/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5773 - accuracy: 0.7094\n",
      "Epoch 16/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5757 - accuracy: 0.7094\n",
      "Epoch 17/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5750 - accuracy: 0.7122\n",
      "Epoch 18/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5739 - accuracy: 0.7136\n",
      "Epoch 19/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5738 - accuracy: 0.7133\n",
      "Epoch 20/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5732 - accuracy: 0.7101\n",
      "Epoch 21/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5723 - accuracy: 0.7090\n",
      "Epoch 22/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5723 - accuracy: 0.7101\n",
      "Epoch 23/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5705 - accuracy: 0.7129\n",
      "Epoch 24/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5698 - accuracy: 0.7168\n",
      "Epoch 25/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5695 - accuracy: 0.7157\n",
      "Epoch 26/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5693 - accuracy: 0.7175\n",
      "Epoch 27/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5684 - accuracy: 0.7165\n",
      "Epoch 28/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5678 - accuracy: 0.7154\n",
      "Epoch 29/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5677 - accuracy: 0.7165\n",
      "Epoch 30/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5675 - accuracy: 0.7172\n",
      "Epoch 31/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5673 - accuracy: 0.7122\n",
      "Epoch 32/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5668 - accuracy: 0.7193\n",
      "Epoch 33/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5646 - accuracy: 0.7182\n",
      "Epoch 34/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5654 - accuracy: 0.7200\n",
      "Epoch 35/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5652 - accuracy: 0.7172\n",
      "Epoch 36/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5643 - accuracy: 0.7193\n",
      "Epoch 37/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5652 - accuracy: 0.7186\n",
      "Epoch 38/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5647 - accuracy: 0.7179\n",
      "Epoch 39/40\n",
      "567/567 [==============================] - 2s 3ms/step - loss: 0.5632 - accuracy: 0.7210\n",
      "Epoch 40/40\n",
      "567/567 [==============================] - 1s 3ms/step - loss: 0.5631 - accuracy: 0.7200\n",
      "283/283 [==============================] - 1s 3ms/step - loss: 0.6056 - accuracy: 0.6792\n",
      "NN Accuracy: 68.50% (1.01%)\n"
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "# estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_neural_network, epochs=40, batch_size=5, verbose=1)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "results = cross_val_score(pipeline, dataX, Y, cv=kfold)\n",
    "print(\"NN Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the ReLU activation function on running for 25 epochs, the K-Fold CV accuracy on K=3 comes out to be 73.5% and the accuracy on K=5 is 71.5%. The Neural Network model trained was a simple one with one hidden layer with 5 neurons."
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
