{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import LogisticRegression, SGDClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_y(dataY):\n",
    "    y = []\n",
    "    for i in range (len(dataY)):\n",
    "        if(dataY[i] > 50):\n",
    "            y.append(0)\n",
    "        else:\n",
    "            y.append(1)\n",
    "    return np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Explicit</th>\n",
       "      <th>Artist_followers</th>\n",
       "      <th>Track_number_on_album</th>\n",
       "      <th>Acousticness</th>\n",
       "      <th>Danceability</th>\n",
       "      <th>Energy</th>\n",
       "      <th>Liveness</th>\n",
       "      <th>Loudness</th>\n",
       "      <th>Speechiness</th>\n",
       "      <th>Tempo</th>\n",
       "      <th>Mode</th>\n",
       "      <th>Key</th>\n",
       "      <th>Valence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.112882</td>\n",
       "      <td>1.012971</td>\n",
       "      <td>-0.703623</td>\n",
       "      <td>-0.253508</td>\n",
       "      <td>-0.056900</td>\n",
       "      <td>-0.257351</td>\n",
       "      <td>-0.321798</td>\n",
       "      <td>-0.287111</td>\n",
       "      <td>1.295366</td>\n",
       "      <td>2.132090</td>\n",
       "      <td>0.865448</td>\n",
       "      <td>0.478965</td>\n",
       "      <td>0.209096</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.898356</td>\n",
       "      <td>0.172558</td>\n",
       "      <td>-0.703623</td>\n",
       "      <td>0.798171</td>\n",
       "      <td>0.424214</td>\n",
       "      <td>-0.688588</td>\n",
       "      <td>-0.492682</td>\n",
       "      <td>0.282796</td>\n",
       "      <td>-0.811102</td>\n",
       "      <td>-0.910119</td>\n",
       "      <td>0.865448</td>\n",
       "      <td>0.752338</td>\n",
       "      <td>0.774957</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.898356</td>\n",
       "      <td>-0.658039</td>\n",
       "      <td>-0.703623</td>\n",
       "      <td>0.764382</td>\n",
       "      <td>0.223151</td>\n",
       "      <td>0.783781</td>\n",
       "      <td>0.019972</td>\n",
       "      <td>0.893382</td>\n",
       "      <td>-0.654093</td>\n",
       "      <td>-0.677720</td>\n",
       "      <td>-1.155199</td>\n",
       "      <td>1.025710</td>\n",
       "      <td>1.138724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.898356</td>\n",
       "      <td>-0.471741</td>\n",
       "      <td>1.732316</td>\n",
       "      <td>-0.619272</td>\n",
       "      <td>-1.528965</td>\n",
       "      <td>0.506556</td>\n",
       "      <td>-0.410955</td>\n",
       "      <td>0.398452</td>\n",
       "      <td>-0.609112</td>\n",
       "      <td>2.593547</td>\n",
       "      <td>0.865448</td>\n",
       "      <td>0.752338</td>\n",
       "      <td>-1.555849</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.898356</td>\n",
       "      <td>0.029319</td>\n",
       "      <td>-0.703623</td>\n",
       "      <td>-0.683893</td>\n",
       "      <td>0.330863</td>\n",
       "      <td>-1.138308</td>\n",
       "      <td>1.097289</td>\n",
       "      <td>-0.823916</td>\n",
       "      <td>-0.601473</td>\n",
       "      <td>-0.142817</td>\n",
       "      <td>0.865448</td>\n",
       "      <td>-1.434643</td>\n",
       "      <td>-1.806445</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Explicit  Artist_followers  Track_number_on_album  Acousticness  \\\n",
       "0  1.112882          1.012971              -0.703623     -0.253508   \n",
       "1 -0.898356          0.172558              -0.703623      0.798171   \n",
       "2 -0.898356         -0.658039              -0.703623      0.764382   \n",
       "3 -0.898356         -0.471741               1.732316     -0.619272   \n",
       "4 -0.898356          0.029319              -0.703623     -0.683893   \n",
       "\n",
       "   Danceability    Energy  Liveness  Loudness  Speechiness     Tempo  \\\n",
       "0     -0.056900 -0.257351 -0.321798 -0.287111     1.295366  2.132090   \n",
       "1      0.424214 -0.688588 -0.492682  0.282796    -0.811102 -0.910119   \n",
       "2      0.223151  0.783781  0.019972  0.893382    -0.654093 -0.677720   \n",
       "3     -1.528965  0.506556 -0.410955  0.398452    -0.609112  2.593547   \n",
       "4      0.330863 -1.138308  1.097289 -0.823916    -0.601473 -0.142817   \n",
       "\n",
       "       Mode       Key   Valence  \n",
       "0  0.865448  0.478965  0.209096  \n",
       "1  0.865448  0.752338  0.774957  \n",
       "2 -1.155199  1.025710  1.138724  \n",
       "3  0.865448  0.752338 -1.555849  \n",
       "4  0.865448 -1.434643 -1.806445  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataX = pd.read_csv('./datasets/spotofy_music_normalized.csv')\n",
    "dataY = pd.read_csv('./datasets/spotofy_music_labels.csv')\n",
    "dataY_multi = pd.read_csv('./datasets/spotofy_music_labels.csv')\n",
    "Y = convert_y(np.array(dataY))\n",
    "dataX.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will implement ANNs on the above data and see the accuracy scores of its prediction of hit vs not hit."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import keras \n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Activation\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalizing the data\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "sc = StandardScaler()\n",
    "X = sc.fit_transform(dataX)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_baseline():\n",
    "\t# create model\n",
    "\tmodel = Sequential()\n",
    "\tmodel.add(Dense(13, input_dim=13, activation='relu'))\n",
    "\tmodel.add(Dense(1, activation='sigmoid')) #Single Layer Sigmoid Binary Classifier == Logistic Regression\n",
    "\t# Compile model\n",
    "\tmodel.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\treturn model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-26-92b082f334d5>:2: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  estimator = KerasClassifier(build_fn=create_baseline, epochs=25, batch_size=5, verbose=0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Baseline with Un-Standardized Data, KFold with K = 5: 68.66% (1.39%)\n",
      "Baseline with Standardized Data, KFold with K = 5: 68.94% (1.08%)\n"
     ]
    }
   ],
   "source": [
    "# evaluate model with standardized dataset\n",
    "estimator = KerasClassifier(build_fn=create_baseline, epochs=25, batch_size=5, verbose=0)\n",
    "kfold = StratifiedKFold(n_splits=5, shuffle=True)\n",
    "results = cross_val_score(estimator, dataX, Y, cv=kfold)\n",
    "print(\"Baseline with Un-Standardized Data, KFold with K = 5: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))\n",
    "results2 = cross_val_score(estimator, X, Y, cv=kfold)\n",
    "print(\"Baseline with Standardized Data, KFold with K = 5: %.2f%% (%.2f%%)\" % (results2.mean()*100, results2.std()*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_neural_network(activation = \"tanh\", neurons = 5):\n",
    "    # create model\n",
    "    model = Sequential()\n",
    "    model.add(Dense(13, input_dim=13, activation='relu'))\n",
    "    model.add(Dense(neurons, activation=activation))\n",
    "    model.add(Dense(1, activation='sigmoid')) #Single Layer Sigmoid Binary Classifier == Logistic Regression\n",
    "    # Compile model\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Tushar\\AppData\\Local\\Temp/ipykernel_4944/3792645775.py:3: DeprecationWarning: KerasClassifier is deprecated, use Sci-Keras (https://github.com/adriangb/scikeras) instead.\n",
      "  estimators.append(('mlp', KerasClassifier(build_fn=create_neural_network, epochs=40, batch_size=5, verbose=1)))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n",
      "567/567 [==============================] - 2s 2ms/step - loss: 0.6425 - accuracy: 0.6552\n",
      "Epoch 2/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.6016 - accuracy: 0.6902\n",
      "Epoch 3/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5932 - accuracy: 0.6969\n",
      "Epoch 4/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5889 - accuracy: 0.7033\n",
      "Epoch 5/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5853 - accuracy: 0.7058\n",
      "Epoch 6/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5826 - accuracy: 0.7043\n",
      "Epoch 7/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5795 - accuracy: 0.7065\n",
      "Epoch 8/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5770 - accuracy: 0.7111\n",
      "Epoch 9/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5751 - accuracy: 0.7128\n",
      "Epoch 10/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5735 - accuracy: 0.7121\n",
      "Epoch 11/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5719 - accuracy: 0.7167\n",
      "Epoch 12/40\n",
      "567/567 [==============================] - 1s 1ms/step - loss: 0.5709 - accuracy: 0.7160\n",
      "Epoch 13/40\n",
      "567/567 [==============================] - 1s 1ms/step - loss: 0.5695 - accuracy: 0.7149\n",
      "Epoch 14/40\n",
      "567/567 [==============================] - 1s 1ms/step - loss: 0.5675 - accuracy: 0.7167\n",
      "Epoch 15/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5674 - accuracy: 0.7171\n",
      "Epoch 16/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5658 - accuracy: 0.7192\n",
      "Epoch 17/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5651 - accuracy: 0.7160\n",
      "Epoch 18/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5647 - accuracy: 0.7188\n",
      "Epoch 19/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5629 - accuracy: 0.7195\n",
      "Epoch 20/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5617 - accuracy: 0.7142\n",
      "Epoch 21/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5616 - accuracy: 0.7174\n",
      "Epoch 22/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5607 - accuracy: 0.7132\n",
      "Epoch 23/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5603 - accuracy: 0.7181\n",
      "Epoch 24/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5589 - accuracy: 0.7195\n",
      "Epoch 25/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5580 - accuracy: 0.7213\n",
      "Epoch 26/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5576 - accuracy: 0.7167\n",
      "Epoch 27/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5570 - accuracy: 0.7259\n",
      "Epoch 28/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5563 - accuracy: 0.7231\n",
      "Epoch 29/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5552 - accuracy: 0.7220\n",
      "Epoch 30/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5547 - accuracy: 0.7266\n",
      "Epoch 31/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5534 - accuracy: 0.7245\n",
      "Epoch 32/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5533 - accuracy: 0.7195\n",
      "Epoch 33/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5528 - accuracy: 0.7252\n",
      "Epoch 34/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5525 - accuracy: 0.7241\n",
      "Epoch 35/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5507 - accuracy: 0.7224\n",
      "Epoch 36/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5506 - accuracy: 0.7287\n",
      "Epoch 37/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5498 - accuracy: 0.7262\n",
      "Epoch 38/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5496 - accuracy: 0.7255\n",
      "Epoch 39/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5477 - accuracy: 0.7291\n",
      "Epoch 40/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5483 - accuracy: 0.7266\n",
      "284/284 [==============================] - 1s 1ms/step - loss: 0.6306 - accuracy: 0.6801\n",
      "Epoch 1/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.6539 - accuracy: 0.6206\n",
      "Epoch 2/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.6195 - accuracy: 0.6704\n",
      "Epoch 3/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.6079 - accuracy: 0.6814\n",
      "Epoch 4/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.6011 - accuracy: 0.6923\n",
      "Epoch 5/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5968 - accuracy: 0.6945\n",
      "Epoch 6/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5941 - accuracy: 0.6937\n",
      "Epoch 7/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5914 - accuracy: 0.6920\n",
      "Epoch 8/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5887 - accuracy: 0.6987\n",
      "Epoch 9/40\n",
      "567/567 [==============================] - 1s 3ms/step - loss: 0.5860 - accuracy: 0.6980\n",
      "Epoch 10/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5845 - accuracy: 0.7008\n",
      "Epoch 11/40\n",
      "567/567 [==============================] - 1s 3ms/step - loss: 0.5817 - accuracy: 0.7008\n",
      "Epoch 12/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5800 - accuracy: 0.7026\n",
      "Epoch 13/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5783 - accuracy: 0.7026\n",
      "Epoch 14/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5765 - accuracy: 0.7001\n",
      "Epoch 15/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5746 - accuracy: 0.7068\n",
      "Epoch 16/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5717 - accuracy: 0.7061\n",
      "Epoch 17/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5713 - accuracy: 0.7082\n",
      "Epoch 18/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5686 - accuracy: 0.7040\n",
      "Epoch 19/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5676 - accuracy: 0.7068\n",
      "Epoch 20/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5660 - accuracy: 0.7100\n",
      "Epoch 21/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5649 - accuracy: 0.7068\n",
      "Epoch 22/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5643 - accuracy: 0.7128\n",
      "Epoch 23/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5642 - accuracy: 0.7107\n",
      "Epoch 24/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5631 - accuracy: 0.7089\n",
      "Epoch 25/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5613 - accuracy: 0.7107\n",
      "Epoch 26/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5614 - accuracy: 0.7118\n",
      "Epoch 27/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5608 - accuracy: 0.7142\n",
      "Epoch 28/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5603 - accuracy: 0.7125\n",
      "Epoch 29/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5590 - accuracy: 0.7181\n",
      "Epoch 30/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5588 - accuracy: 0.7156\n",
      "Epoch 31/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5565 - accuracy: 0.7220\n",
      "Epoch 32/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5577 - accuracy: 0.7192\n",
      "Epoch 33/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5568 - accuracy: 0.7164\n",
      "Epoch 34/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5573 - accuracy: 0.7213\n",
      "Epoch 35/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5567 - accuracy: 0.7167\n",
      "Epoch 36/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5549 - accuracy: 0.7192\n",
      "Epoch 37/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5561 - accuracy: 0.7146\n",
      "Epoch 38/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5549 - accuracy: 0.7192\n",
      "Epoch 39/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5541 - accuracy: 0.7209\n",
      "Epoch 40/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5545 - accuracy: 0.7188\n",
      "284/284 [==============================] - 1s 1ms/step - loss: 0.6261 - accuracy: 0.6730\n",
      "Epoch 1/40\n",
      "567/567 [==============================] - 2s 2ms/step - loss: 0.6451 - accuracy: 0.6465\n",
      "Epoch 2/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.6207 - accuracy: 0.6663\n",
      "Epoch 3/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.6099 - accuracy: 0.6804\n",
      "Epoch 4/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.6035 - accuracy: 0.6921\n",
      "Epoch 5/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5996 - accuracy: 0.6949\n",
      "Epoch 6/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5970 - accuracy: 0.6935\n",
      "Epoch 7/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5952 - accuracy: 0.6981\n",
      "Epoch 8/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5931 - accuracy: 0.6981\n",
      "Epoch 9/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5914 - accuracy: 0.6977\n",
      "Epoch 10/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5904 - accuracy: 0.7013\n",
      "Epoch 11/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5891 - accuracy: 0.7006\n",
      "Epoch 12/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5882 - accuracy: 0.7016\n",
      "Epoch 13/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5874 - accuracy: 0.7016\n",
      "Epoch 14/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5863 - accuracy: 0.6995\n",
      "Epoch 15/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5857 - accuracy: 0.7027\n",
      "Epoch 16/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5845 - accuracy: 0.7009\n",
      "Epoch 17/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5839 - accuracy: 0.6999\n",
      "Epoch 18/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5832 - accuracy: 0.7034\n",
      "Epoch 19/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5826 - accuracy: 0.7006\n",
      "Epoch 20/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5817 - accuracy: 0.7037\n",
      "Epoch 21/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5807 - accuracy: 0.7016\n",
      "Epoch 22/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5799 - accuracy: 0.7052\n",
      "Epoch 23/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5792 - accuracy: 0.7027\n",
      "Epoch 24/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5780 - accuracy: 0.7037\n",
      "Epoch 25/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5778 - accuracy: 0.7076\n",
      "Epoch 26/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5770 - accuracy: 0.7052\n",
      "Epoch 27/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5764 - accuracy: 0.7066\n",
      "Epoch 28/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5756 - accuracy: 0.7122\n",
      "Epoch 29/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5755 - accuracy: 0.7066\n",
      "Epoch 30/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5737 - accuracy: 0.7066\n",
      "Epoch 31/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5740 - accuracy: 0.7080\n",
      "Epoch 32/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5724 - accuracy: 0.7080\n",
      "Epoch 33/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5729 - accuracy: 0.7097\n",
      "Epoch 34/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5718 - accuracy: 0.7094\n",
      "Epoch 35/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5709 - accuracy: 0.7073\n",
      "Epoch 36/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5713 - accuracy: 0.7090\n",
      "Epoch 37/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5705 - accuracy: 0.7133\n",
      "Epoch 38/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5700 - accuracy: 0.7140\n",
      "Epoch 39/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5688 - accuracy: 0.7140\n",
      "Epoch 40/40\n",
      "567/567 [==============================] - 1s 2ms/step - loss: 0.5691 - accuracy: 0.7083\n",
      "283/283 [==============================] - 1s 1ms/step - loss: 0.5976 - accuracy: 0.6883\n",
      "NN Accuracy: 68.05% (0.63%)\n"
     ]
    }
   ],
   "source": [
    "estimators = []\n",
    "estimators.append(('standardize', StandardScaler()))\n",
    "estimators.append(('mlp', KerasClassifier(build_fn=create_neural_network, epochs=40, batch_size=5, verbose=1)))\n",
    "pipeline = Pipeline(estimators)\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True)\n",
    "results = cross_val_score(pipeline, dataX, Y, cv=kfold)\n",
    "print(\"NN Accuracy: %.2f%% (%.2f%%)\" % (results.mean()*100, results.std()*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the ReLU activation function on running for 25 epochs, the K-Fold CV accuracy on K=3 comes out to be 73.5% and the accuracy on K=5 is 71.5%. The Neural Network model trained was a simple one with one hidden layer with 5 neurons."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the tanh activation function on running for 40 epochs, the K-Fold CV accuracy on K=3 comes out to be 66.89%. The Neural Network model trained was a simple one with one hidden layer with 10 neurons.\n",
    "and the accuracy on K=5 is 67.93% --> hiddlen layer with 5 neurons\n",
    "\n",
    "> Accuracy: 66.89% (1.32%)\n",
    "\n",
    ">Accuracy: 67.93% (0.89%)\n",
    "\n",
    ">Accuracy: 69.20% (0.90%) --> leaky_relu, 5 neurons, k=5\n",
    "\n",
    ">NN Accuracy: 68.75% (0.31%) --> leaky_relu, 5 neurons, k=3\n",
    "\n",
    ">NN Accuracy: 71.3% (1.16%) --> tanh , 5 neurons, k=5, epcohs 25\n",
    "\n",
    "> Accuracy : 71.8% --> tanh, 5 neurons, standarized, 40 epoch, k=3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.67647058, 0.68470585, 0.67491168, 0.6949352 , 0.65135455])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
  },
  "kernelspec": {
   "display_name": "Python 3.8.5 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
